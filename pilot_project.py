# -*- coding: utf-8 -*-
"""Pilot_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qjtj7kEPj2kPJz8PNTOLvEVgUsvosSik

# Import Libraries and Data
"""

# Import Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


from google.colab import drive
import gdown
gdown.download('https://drive.google.com/uc?id=1OB_GMPQwlIGFpn6KudUTf-Siq85cWU4c',
               'train.csv')
gdown.download('https://drive.google.com/uc?id=1euXRCik-3y-Ip9Z0EO6WIK7gKBFexBAL',
               'test.csv')

# Load datasets

train_df = pd.read_csv("/content/train.csv", delimiter=',')
test_df = pd.read_csv("/content/test.csv", delimiter=',')

"""# Cleaning"""

# Understand missing values

train_df.describe(include="all")

na_counts = train_df.isnull().sum()

missing = train_df.isnull().sum()
missing = missing[missing > 0]
missing.sort_values(inplace=True)
missing.plot.bar()

##############################
# ----Data Cleaning Fcn ---- #
##############################

def data_cleaner(dt):
  dt['SalePrice'] = np.log(dt['SalePrice'])

  dt = dt.drop('Id', axis=1)

  ### Lot Frontage
  dt["LotFrontage"] = dt.groupby(["Street","Neighborhood"])["LotFrontage"].transform(lambda x:x.fillna(x.median()))
  ### Alley
  dt["Alley"]= dt["Alley"].fillna("None")
  ### MasVnrType & MasVnrArea
  dt["MasVnrArea"] = dt.groupby(["Exterior1st", "Exterior2nd"])["MasVnrArea"].transform(lambda x: x.fillna(x.median()) if not x.mode().empty else 0)
  dt["MasVnrType"] = np.where(dt["MasVnrArea"] == 0, "None",dt["MasVnrType"])
  dt["MasVnrType"] = dt.groupby(["MasVnrArea", "Exterior1st", "Exterior2nd"])["MasVnrType"].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'None'))
  ### BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2
  dt[["BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2"]]=dt[["BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2"]].fillna("None")
  ### Electrical
  dt["Electrical"] = dt["Electrical"].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'None'))
  # filling missing fireplace column with None
  dt['FireplaceQu'] = dt['FireplaceQu'].fillna('None')

  ### GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond
  dt[["GarageType", "GarageYrBlt", "GarageFinish", "GarageQual", "GarageCond"]] = dt[["GarageType", "GarageYrBlt", "GarageFinish", "GarageQual", "GarageCond"]].fillna("None")
  ### PoolQC
  dt["PoolQC"] = dt["PoolQC"].fillna("None")
  ### Fence
  dt["Fence"] = dt["Fence"].fillna("None")
  ### MiscFeature
  dt["MiscFeature"] = dt["MiscFeature"].fillna("None")

  ## Convert Time variables to Integer Age

  dt["Age"] = 2010 - dt["YearBuilt"]
  dt = dt.drop(columns=['YearBuilt'])
  #dt['Age'] = dt.fillna(0)

  dt["YearsSinceRemodeled"] = 2010 - dt["YearRemodAdd"]
  dt = dt.drop(columns=['YearRemodAdd'])
  #dt["YearsSinceRemodeled"] = dt["YearsSinceRemodeled"].fillna(0)

  dt["GarageYrBlt"] = pd.to_numeric(dt["GarageYrBlt"], errors='coerce')
  dt["GarageAge"] = 2010 - dt["GarageYrBlt"]
  dt = dt.drop(columns=['GarageYrBlt'])
  dt['GarageAge'] = dt['GarageAge'].fillna(0)


  dt["TimeSinceSold"] = 2010 - dt["YrSold"] + ((12 - dt["MoSold"]) / 12)
  #dt['TimeSinceSold'] = dt['TimeSinceSold'].fillna(0)
  dt = dt.drop(columns=['YrSold'])
  dt = dt.drop(columns=['MoSold'])


  # Create Dummies

  encoded_dt = pd.get_dummies(dt, columns=dt.select_dtypes(include=['object', 'category']).columns.tolist())

  return encoded_dt

########################
########################

# Checking the fcn

cleaned_train = data_cleaner(train_df)

cleaned_train

"""# **Testing Feature Selection Algorithms**

In this analysis, we will evaluate the effectiveness of various feature selection algorithms in two distinct scenarios based on the relationship between the number of rows (n) and columns (m) in our dataset. Specifically, we will assess:

1. **Evaluating Feature Selection Algorithms when \( n > m \)**
2. **Evaluating Feature Selection Algorithms when \( m > n \)**

**Where:**
- \( n \) is the number of rows (observations).
- \( m \) is the number of columns (features).

---

## **Objective**

The primary goal is to evaluate the **Root Mean Squared Error (RMSE)** of a standard linear regression model across three different feature selection algorithms, utilizing **5-fold cross-validation** and **Booststrapping** to ensure robust results.

---

## **Feature Selection Algorithms Under Evaluation**

1. **Select K Best**
   - Uses mutual information regression to select the top k features based on their individual performance in predicting the target variable.

2. **Variance Threshold**
   - Eliminates features with low variance, retaining only those that contribute meaningful variability to the dataset.

3. **Recursive Feature Elimination (RFE) with Lasso Regression**
   - This method recursively removes features and builds a model on the remaining attributes, leveraging Lasso regression to promote sparsity in feature selection.

---

## **Methodology**

To create a scenario where \( m > n \), we will utilize a random number generator to obtain a consistent set of random index numbers, with a length of \( m - 25 \). This method ensures that the random indices remain constant across each feature selection algorithm during the experiment, thus minimizing variance and bias in the results. For the scenerio where \( n > m \), we utilize the entire provided training dataset. We use bootstrapping in
a few ways:
1. To calculate robust RMSE values and confidence intervals for the baseline model.
2. To calculate robust RMSE values and confidence intervals for the full data partition.
3. To calculate robust RMSE and Percent Features in Common measures and confidence intervals for the subset data partition - not necessarily because of variability in cross-validation fold randomization, but because of the variation in features selected from the high-dimensionality scenerio.



"""

############################################################
# ---------- Testing Feature Selection Algorithms ----------
############################################################

from sklearn.linear_model import LinearRegression, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import Normalizer
from sklearn.feature_selection import SelectKBest, RFE, VarianceThreshold, SelectFromModel, mutual_info_regression
from sklearn.pipeline import Pipeline
from sklearn.metrics import root_mean_squared_error, make_scorer
from sklearn.model_selection import cross_val_predict, KFold


feature_selection_algos = [
    ('SelectKBest', SelectKBest(mutual_info_regression,
                                k = 25)), # mutual_info_regression, r_regression, f_regression
    ('RFE', RFE(estimator = Lasso(),
                n_features_to_select = 25,
                step = 1)),
    ('VarianceThreshold', VarianceThreshold(threshold = 1.9)), # about 25 features over this threshold
    ('SelectFromModel_Lasso', SelectFromModel(estimator = Lasso(),
                                        max_features = 25)),
     ('SelectFromModel_Tree', SelectFromModel(estimator = DecisionTreeRegressor(),
                                        max_features = 25))
]

model = LinearRegression()
cv = KFold(n_splits=5, shuffle=True)

y, X = cleaned_train['SalePrice'], cleaned_train.drop('SalePrice', axis=1)

######################
## Running All Tests
######################

# BOOTSTRAP CONTROL:
n_bootstrap = 100

####################
# BASELINE MODEL

lasso_rmse = []
print("Running control model")
for iter in range(0, n_bootstrap):
  lasso_pred = cross_val_predict(Lasso(), X, y, cv=cv)
  lasso_rmse.append(np.sqrt(np.mean((np.exp(y) - np.exp(lasso_pred)) ** 2)))


lasso_cv_rmse = np.mean(lasso_rmse)

# Bootstraping Begins
bootstrap_rmse_results = {name: [] for name, _ in feature_selection_algos}
bootstrap_common_feature_percentages = {name: [] for name, _ in feature_selection_algos}

####################
# FULL PARTITION
full_rmse_results = {}
full_rmse_ci = {}
full_rmse_std = {}
selected_features_full = {}

for name, selector in feature_selection_algos:
    print(f'Running "full" partition for {name}')
    selector.fit(X, y)
    X_full_transformed = selector.transform(X)

    # Store selected features for 'full'
    if hasattr(selector, 'get_support'):
        selected_features_full[name] = X.columns[selector.get_support()]
    elif hasattr(selector, 'get_feature_names_out'):
        selected_features_full[name] = selector.get_feature_names_out(input_features=X.columns)
    else:
        selected_features_full[name] = []

    temp_rmse_results = []

    for iter in range(0, n_bootstrap):

      y_pred = cross_val_predict(model, X_full_transformed, y, cv=cv)
      temp_rmse_results.append(np.sqrt(np.mean((np.exp(y) - np.exp(y_pred)) ** 2)))

    full_rmse_results[name] = np.mean(temp_rmse_results)
    full_rmse_std[name] = np.std(temp_rmse_results)
    ci_low, ci_high = np.percentile(temp_rmse_results, [2.5, 97.5])
    full_rmse_ci[name] = (ci_low, ci_high)

####################
# SUBSET PARTITION
for bootstrap_iteration in range(n_bootstrap):
    print(f'Running bootstrap sample {bootstrap_iteration + 1}/{n_bootstrap}')

    # Create the random subset for the bootstrap sample
    subset_indices = np.random.randint(0, len(cleaned_train), size=len(cleaned_train.columns) - 50)# np.random.choice(range(len(X)), size=len(X.columns) - 50, replace=True)

    for name, selector in feature_selection_algos:
        # Fit selector to the 'subset'
        X_subset = X.iloc[subset_indices]
        y_subset = y.iloc[subset_indices]
        selector.fit(X_subset, y_subset)
        X_subset_transformed = selector.transform(X)

        # Calculate RMSE for the 'subset'

        subset_y_pred = cross_val_predict(model, X_subset_transformed, y, cv=cv)
        bootstrap_rmse_results[name].append(np.sqrt(np.mean((np.exp(y) - np.exp(subset_y_pred)) ** 2)))


        # Percentage of feature commonality
        common_feat_list = [
            feature for feature in selected_features_full[name]
            if feature in X.columns[selector.get_support()]
        ]
        common_percentage = len(common_feat_list) / len(selected_features_full[name])

        # Store the common feature percentage
        bootstrap_common_feature_percentages[name].append(common_percentage)

# Calculate confidence intervals for percentage of feature commonality for each algorithm
for name in bootstrap_rmse_results:
    common_feat_array = np.array(bootstrap_common_feature_percentages[name])

    # Common feature percentage confidence intervals
    common_ci_low, common_ci_high = np.percentile(common_feat_array, [2.5, 97.5])

# Create a dictionary to store the formatted RMSE results
formatted_rmse_results = {
    'Full': [],
    'Full 95% CI Lower': [],
    'Full 95% CI Upper': [],
    'Subset': [],
    'Subset 95% CI Lower': [],
    'Subset 95% CI Upper': []
}


for name in bootstrap_rmse_results:
    # Get the full RMSE value
    full_rmse = full_rmse_results[name]
    # Confidence Int for full subset
    full_rmse_ci_low, full_rmse_ci_high = full_rmse_ci[name]

    # Calculate the mean and confidence interval for the subset RMSE
    subset_rmse_array = np.array(bootstrap_rmse_results[name])
    subset_rmse_mean = subset_rmse_array.mean()
    subset_rmse_ci_low, subset_rmse_ci_high = np.percentile(subset_rmse_array, [2.5, 97.5])

    formatted_rmse_results['Full'].append(full_rmse)
    formatted_rmse_results['Full 95% CI Lower'].append(full_rmse_ci_low)
    formatted_rmse_results['Full 95% CI Upper'].append(full_rmse_ci_high)
    formatted_rmse_results['Subset'].append(subset_rmse_mean)
    formatted_rmse_results['Subset 95% CI Lower'].append(subset_rmse_ci_low)
    formatted_rmse_results['Subset 95% CI Upper'].append(subset_rmse_ci_high)

rmse_df = pd.DataFrame(formatted_rmse_results, index=[name for name, _ in feature_selection_algos])

rmse_df = np.round(rmse_df, 2)

control_lasso_rmse = np.round(lasso_cv_rmse, 2)
lasso_rmse_ci_low, lasso_rmse_ci_high = np.percentile(lasso_rmse, [2.5, 97.5])

# Append the Control Lasso row to the DataFrame
control_row = pd.DataFrame({
    'Full': [control_lasso_rmse],
    'Full 95% CI Lower':[lasso_rmse_ci_low],
    'Full 95% CI Upper': [lasso_rmse_ci_high],
    'Subset': [' '],
    'Subset 95% CI Lower': [' '],
    'Subset 95% CI Upper': [' ']
}, index=['Control Lasso'])

# Combine the original DataFrame with the control row
rmse_df = pd.concat([rmse_df, control_row])

rmse_df

# Standard Deviation between Full and Subset RMSE Values
rmse_stdevs = {
    'Full': [],
    'Subset': [],
}

for name in bootstrap_rmse_results:
    # FULL RMSE STD
    full_std = full_rmse_std[name]

    # SUBSET RMSE STD
    subset_rmse_std = np.std(bootstrap_rmse_results[name])

    rmse_stdevs['Full'].append(full_std)
    rmse_stdevs['Subset'].append(subset_rmse_std)

rmse_std_df = pd.DataFrame(rmse_stdevs, index=[name for name, _ in feature_selection_algos])

np.round(rmse_std_df, 2)

formatted_percentage_results = {
    'Percentage': [],
    'Percentage 95% CI Lower': [],
    'Percentage 95% CI Upper': []
}

# Iterate over each algorithm to fill in the DataFrame
for name in bootstrap_common_feature_percentages:
    # Get the array of common feature percentages
    percentage_array = np.array(bootstrap_common_feature_percentages[name])

    # Calculate the mean and confidence interval for the percentages
    percentage_mean = percentage_array.mean()
    percentage_ci_low, percentage_ci_high = np.percentile(percentage_array, [2.5, 97.5])

    # Add the values to the dictionary
    formatted_percentage_results['Percentage'].append(percentage_mean)
    formatted_percentage_results['Percentage 95% CI Lower'].append(percentage_ci_low)
    formatted_percentage_results['Percentage 95% CI Upper'].append(percentage_ci_high)

percentage_df = pd.DataFrame(formatted_percentage_results, index=[name for name, _ in feature_selection_algos])


np.round(percentage_df, 3)

# What are the common features across full subset?

select_algorithms = ['SelectKBest', 'RFE', 'VarianceThreshold', 'SelectFromModel_Lasso']


# FULL
common_features_full = set(selected_features_full[select_algorithms[0]])

for algo in select_algorithms[1:]:

  features_algo = set(selected_features_full[algo])

  common_features_full &= features_algo

common_feat_list_full = list(common_features_full)

from scipy.stats import pearsonr

unsure_features = []

for feature in common_feat_list_full:

    coef, p_value = pearsonr(cleaned_train['SalePrice'], cleaned_train[feature])

    if coef > 0.1 and p_value < 0.05:
        print(f"{feature} increases house prices [corr_coef: {coef:.2f}, p-value: {p_value:.2f}].", "\n")
    elif coef < -0.1 and p_value < 0.05:
        print(f"{feature} decreases house prices [corr_coef: {coef:.2f}, p-value: {p_value:.2f}].", "\n")
    else:
        unsure_features.append(feature)
        print(f"**Unsure about {feature}.** Correlation coefficient: {coef:.2f}, p-value: {p_value:.2f}", "\n")

# Lasso Comparison
from sklearn.linear_model import LassoCV, Lasso
from sklearn.preprocessing import StandardScaler
import numpy as np

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

alpha = 0.01

lasso = Lasso(alpha=alpha).fit(X_scaled, y)

# Count non-zero coefficients
non_zero_count = np.sum(lasso.coef_ != 0)
print(f'Number of non-zero coefficients: {non_zero_count}')

# If not within the desired range, adjust alpha
while non_zero_count < 10 or non_zero_count > 15:
    if non_zero_count > 15:
        alpha *= 1.1  # Increase alpha to increase regularization (fewer features)
    elif non_zero_count < 10:
        alpha /= 1.1  # Decrease alpha to decrease regularization (more features)

    lasso = Lasso(alpha=alpha).fit(X_scaled, y)
    non_zero_count = np.sum(lasso.coef_ != 0)
    print(f'Adjusted alpha: {alpha}, Non-zero coefficients: {non_zero_count}')

selected_features = np.array(X.columns)[lasso.coef_ != 0]
selected_coefficients = lasso.coef_[lasso.coef_ != 0]

# Create a DataFrame to display features and coefficients
ls_mod_features = pd.DataFrame({
    'Feature': selected_features,
    'Coefficient': selected_coefficients
}).sort_values(by='Coefficient', ascending=False).reset_index(drop=True)

np.round(ls_mod_features, 4).set_index('Feature')