<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Pavlo Mysak" />
  <meta name="dcterms.date" content="2025-09-28" />
  <title>Notes on Total Variance</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="latex.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Notes on Total Variance</h1>
<p class="author">Pavlo Mysak</p>
<p class="date">2025-09-28</p>
</header>
<p>Within my first month of working toward my masterâ€™s degree at Boston
University, I noticed the same concept was popping up in totally
different classes, but under different names and from different angles.
It felt like dÃ©jÃ  vu, but math-y.</p>
<p>That concept was total variance. And while the math itself is
straightforward enough, what caught my attention is how different fields
frame and interpret it. I havenâ€™t seen a post tying these perspectives
together, so I figured Iâ€™d take a shot at formalizing this idea.</p>
<h1 id="law-of-total-variance-eves-law">Law of Total Variance (Eveâ€™s
Law)</h1>
<p>Letâ€™s start with the probability theory side of things. The law of
total variance tells us:</p>
<p><span
class="math display"><em>V</em><em>a</em><em>r</em>(<em>Y</em>)â€„=â€„ğ”¼[<em>V</em><em>a</em><em>r</em>(<em>Y</em>|<em>X</em>)]â€…+â€…<em>V</em><em>a</em><em>r</em>[ğ”¼(<em>Y</em>|<em>X</em>)]</span></p>
<p>If youâ€™ve never seen this before it may look a little cryptic or
suspicious, But itâ€™s called a <em>law</em> for a reason. And you donâ€™t
just have to take my (or Eveâ€™s) word for it: with the law of iterated
expectations (Adamâ€™s Law) and some algebra, you can prove it yourself.
Turns out Adam &amp; Eveâ€™s contributions to probability theory are
vastly underappreciated.<br />
</p>
<p>Iâ€™ll skip the proof here (<a
href="https://statproofbook.github.io/P/var-tot">see references</a><span
class="citation" data-cites="lawtotvar"></span>), but the key idea is
that the total variance of <span class="math inline"><em>Y</em></span>
can be split into two pieces:<br />
- the <em>within-group variance</em>, <span
class="math inline">ğ”¼[<em>V</em><em>a</em><em>r</em>(<em>Y</em>|<em>X</em>)]</span><br />
- the <em>between-group variance</em>, <span
class="math inline"><em>V</em><em>a</em><em>r</em>(ğ”¼[<em>Y</em>|<em>X</em>])</span><br />
</p>
<p>If youâ€™ve ever seen ANOVA, this probably rings a bell. In that world,
the whole point is to compare between-group variance to within-group
variance: if the former is substantially larger, itâ€™s evidence that
group means are likely different.</p>
<p>Thatâ€™s one way to read this formula. But it can also be shown in a
perspective that puts this decomposition in <a
href="https://andrewcharlesjones.github.io/journal/epi-ali-uncertainty.html">the
language of uncertainty</a><span class="citation"
data-cites="aleat_epist"></span>. Specifically:<br />
</p>
<ul>
<li><p>The first term, <span
class="math inline">ğ”¼[<em>V</em><em>a</em><em>r</em>(<em>Y</em>|<em>X</em>)]</span>,
corresponds to <strong>aleatoric uncertainty</strong>: the inherent
randomness and noise built into the data-generating process. That is,
itâ€™s the â€œnoise weâ€™re stuck with.â€<br />
</p></li>
<li><p>The second term, <span
class="math inline"><em>V</em><em>a</em><em>r</em>(ğ”¼[<em>Y</em>|<em>X</em>])</span>,
corresponds to <strong>epistemic uncertainty</strong>: uncertainty that
comes from not knowing enough about the data-generating process. In
other words, uncertainty that could shrink if we gathered more data or
adjusted model parameters.<br />
</p></li>
</ul>
<p>In Bayesian inference, this split isnâ€™t just a neat decomposition;
itâ€™s baked into how we think about likelihoods and posteriors. Aleatoric
uncertainty is the expected noise from the sampling model. Epistemic
uncertainty is the variation induced by the posterior over parameters.
And crucially, as we collect more data, epistemic uncertainty tends to
fade away, which lines up perfectly with the intuition.</p>
<h1 id="biasvariance-tradeoff">Biasâ€“Variance Tradeoff</h1>
<p>Now letâ€™s switch gears to machine learning. A classic idea here is
the <a
href="https://mlu-explain.github.io/bias-variance/"><em>biasâ€“variance
tradeoff</em></a><span class="citation"
data-cites="biasvartradeoff"></span>. Youâ€™ve probably heard the
high-level version before: models with too much flexibility tend to have
high variance, while models that are too simple/rigid tend to have high
bias. But letâ€™s actually derive where this decomposition comes from.</p>
<p>Suppose we want to measure the error of a predictive model <span
class="math inline"><em>y</em>(<em>x</em>;â€†<em>D</em>)</span>, where
<span class="math inline"><em>D</em></span> is a dataset. A natural way
to do this is to look at the squared deviation from the true signal
<span class="math inline"><em>h</em>(<em>x</em>)</span>:</p>
<p><span
class="math display">[<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…<em>h</em>(<em>x</em>)]<sup>2</sup></span></p>
<p>Here:<br />
- <span class="math inline"><em>y</em>(<em>x</em>;â€†<em>D</em>)</span> is
our prediction given a particular dataset <span
class="math inline"><em>D</em></span><br />
- <span class="math inline"><em>h</em>(<em>x</em>)</span> is the â€œground
truthâ€ or optimal prediction<br />
</p>
<p>The trick is to rewrite this error by pivoting around the expected
prediction, <span
class="math inline">ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]</span>.
In other words, add and subtract the same thing:</p>
<p><span
class="math display">[<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…+â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…âˆ’â€…<em>h</em>(<em>x</em>)]<sup>2</sup></span></p>
<p>Now expand it with <span
class="math inline">(<em>a</em>â€…+â€…<em>b</em>)<sup>2</sup>â€„=â€„<em>a</em><sup>2</sup>â€…+â€…<em>b</em><sup>2</sup>â€…+â€…2<em>a</em><em>b</em></span>:</p>
<p><span
class="math display">[<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]]<sup>2</sup>â€…+â€…[ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…âˆ’â€…<em>h</em>(<em>x</em>)]<sup>2</sup>â€…+â€…2(<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)])(ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…âˆ’â€…<em>h</em>(<em>x</em>))</span></p>
<p>To turn this into a proper measure of error, we take the expectation
over dataset <span class="math inline"><em>D</em></span> (think of it as
averaging over many possible training samples):</p>
<p><span
class="math display">ğ”¼<sub><em>D</em></sub>[(<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)])<sup>2</sup>]â€…+â€…ğ”¼<sub><em>D</em></sub>[(ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…âˆ’â€…<em>h</em>(<em>x</em>))<sup>2</sup>]â€…+â€…ğ”¼<sub><em>D</em></sub>[cross
term]</span></p>
<p>Hereâ€™s the nice part: with a bit of algebra, you can show the cross
term vanishes. (Quick hint: itâ€™s the covariance between <span
class="math inline"><em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]</span>
and the constant term <span
class="math inline">ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…âˆ’â€…<em>h</em>(<em>x</em>)</span>,
which is zero.)</p>
<p>So weâ€™re left with:</p>
<p><span
class="math display">ğ”¼<sub><em>D</em></sub>[(<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)])<sup>2</sup>]â€…+â€…[ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…âˆ’â€…<em>h</em>(<em>x</em>)]<sup>2</sup></span></p>
<p>And now we can name the two pieces:<br />
</p>
<ul>
<li><p><span
class="math inline">ğ”¼<sub><em>D</em></sub>[(<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)])<sup>2</sup>]</span>
is the <strong>variance</strong></p></li>
<li><p><span
class="math inline">[ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…âˆ’â€…<em>h</em>(<em>x</em>)]<sup>2</sup></span>
is the <strong>bias</strong> squared</p></li>
</ul>
<p>Thatâ€™s the biasâ€“variance decomposition. It tells us that model error
isnâ€™t just one homogenous thing, rather itâ€™s the sum of two different
sources.</p>
<p>... doesnâ€™t this look awfully familiar?</p>
<h1 id="the-comparison">The Comparison</h1>
<p>We know that:<br />
<span
class="math inline">ğ”¼[<em>V</em><em>a</em><em>r</em>(<em>Y</em>|<em>X</em>)]â†’</span>
<strong>aleatoric uncertainty</strong><br />
<span
class="math inline"><em>V</em><em>a</em><em>r</em>(ğ”¼[<em>Y</em>|<em>X</em>])â†’</span>
<strong>epistemic uncertainty</strong><br />
<span
class="math inline">ğ”¼<sub><em>D</em></sub>[(<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)])<sup>2</sup>]â†’</span>
<strong>variance</strong><br />
<span
class="math inline">[ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…âˆ’â€…<em>h</em>(<em>x</em>)]<sup>2</sup>â€„â†’â€„<strong>bias</strong><sup>2</sup></span><br />
</p>
<p>How can we match up these terms based on similarity? Well, letâ€™s
start with the easy one.</p>
<p>Aleatoric uncertainty and the variance term are clearly long-lost
cousins. Both are expectations of a squared deviation, and if you stare
at the biasâ€“variance expression long enough, youâ€™ll notice <span
class="math inline">ğ”¼<sub><em>D</em></sub>[(<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)])<sup>2</sup>]</span>
is literally the variance of <span
class="math inline"><em>y</em>(<em>x</em>;â€†<em>D</em>)</span>. And what
is <span class="math inline"><em>y</em>(<em>x</em>;â€†<em>D</em>)</span>,
really, if not â€œ<span class="math inline"><em>Y</em></span> given <span
class="math inline"><em>X</em></span>â€ in disguise?</p>
<p>So: <span
class="math display">ğ”¼<sub><em>D</em></sub>[(<em>y</em>(<em>x</em>;â€†<em>D</em>)â€…âˆ’â€…ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)])<sup>2</sup>]â€„=â€„ğ”¼[<em>V</em><em>a</em><em>r</em>(<em>Y</em>|<em>X</em>)]</span>
Ergo, <strong>variance = aleatoric uncertainty</strong>. Nice and
tidy.</p>
<p>But what about the other half? Does that mean the bias term should
line up with epistemic uncertainty?</p>
<p>Letâ€™s think it through. Our bias, <span
class="math display">[ğ”¼<sub><em>D</em></sub>[<em>y</em>(<em>x</em>;â€†<em>D</em>)]â€…âˆ’â€…<em>h</em>(<em>x</em>)]<sup>2</sup>,</span>
measures the systematic gap between the average prediction (across
datasets) and the true signal <span
class="math inline"><em>h</em>(<em>x</em>)</span>. Even if we trained on
infinitely many datasets, if our model is misspecified, this term wonâ€™t
vanish. Thatâ€™s the heart of bias: itâ€™s structural error baked into the
model.</p>
<p>Epistemic uncertainty, by contrast, is the part of our variance that
<em>can</em> vanish with more information, at least in principle. It
reflects what we donâ€™t yet know about the data-generating process, and
with more data (or a more flexible model) it shrinks.</p>
<p>Mathematically, epistemic uncertainty is written as <span
class="math display"><em>V</em><em>a</em><em>r</em>(ğ”¼[<em>Y</em>|<em>X</em>])â€„=â€„ğ”¼â€Š[(ğ”¼[<em>Y</em>|<em>X</em>]â€…âˆ’â€…ğ”¼[<em>Y</em>])<sup>2</sup>].</span>
At first glance, this doesnâ€™t look much like bias at all. In fact,</p>
<p><span
class="math display">ğ”¼[(ğ”¼[<em>Y</em>|<em>X</em>]â€…âˆ’â€…ğ”¼[<em>Y</em>])<sup>2</sup>]â€„â‰ â€„(ğ”¼[<em>Y</em>|<em>X</em>]â€…âˆ’â€…<em>Y</em>)<sup>2</sup></span></p>
<p>and unfortunately, Adam &amp; Eve canâ€™t rescue us from that
algebra.</p>
<p>But both terms are doing the same kind of job: theyâ€™re quantifying a
gap between â€œwhat we knowâ€ and â€œwhatâ€™s actually out there.â€</p>
<p>Bias squares the distance between our modelâ€™s average prediction and
the truth. The epistemic term squares the distance between different
possible truths (the conditional means) and the global average. Theyâ€™re
not equal, but they rhyme.</p>
<p>So the relationship is this:</p>
<ul>
<li><p><strong>Bias</strong> makes the gap <em>explicit</em>: itâ€™s your
modelâ€™s systematic error, locked into its parameters or functional form.
This error wonâ€™t disappear unless the model itself gets better.</p></li>
<li><p><strong>Epistemic uncertainty</strong> makes the gap
<em>probabilistic</em>: itâ€™s the spread in our beliefs about the
process, which can shrink as data accumulates or the model grows more
expressive.</p></li>
</ul>
<p>Two sides of the same coin (one deterministic, the other
probabilistic) but both about our ignorance of the true process.</p>
<p>So hereâ€™s the mapping in a nutshell:</p>
<ul>
<li><p><strong>Variance</strong> <span class="math inline">â†”ï¸</span>
<strong>aleatoric uncertainty</strong> (noise weâ€™re stuck
with).</p></li>
<li><p><strong>Bias</strong> <span class="math inline">â†”ï¸</span>
<strong>epistemic uncertainty</strong> (ignorance we might
reduce).</p></li>
</ul>
<p>And once you see it this way, the two decompositions stop looking
like separate ideas from two different courses, and more like the same
story told in two different dialects.</p>
<h1 class="unnumbered" id="references">References</h1>
<div class="thebibliography">
<p><span>9</span></p>
<p>Andrew Charles Jones (2022). <em>Epistemic and aleotoric uncertainty
in statistical models</em> Technical Blog URL: <a
href="https://andrewcharlesjones.github.io/journal/epi-ali-uncertainty.html"
class="uri">https://andrewcharlesjones.github.io/journal/epi-ali-uncertainty.html</a>.</p>
<p>Jared Wilbur &amp; Brent Werness (2021). <em>The Bias Variance
Tradeoff</em>. MLU Explain Series URL: <a
href="https://mlu-explain.github.io/bias-variance/"
class="uri">https://mlu-explain.github.io/bias-variance/</a>.</p>
<p>Joram Soch (2021). <em>Proof: Law of Total Variance</em>. The Book of
Statistical Proofs, Proof #292. URL: <a
href="https://statproofbook.github.io/P/var-tot"
class="uri">https://statproofbook.github.io/P/var-tot</a>. DOI: <a
href="10.5281/zenodo.4305949"
class="uri">10.5281/zenodo.4305949</a>.</p>
</div>
<p><em>Note: These references are not the original sources of the
concepts, but rather helpful resources I recommend to any reader not
familiar with them.</em></p>
</body>
</html>
